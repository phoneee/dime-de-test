[2023-12-20T19:33:04.548+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: financial_data_processing.process_dividends_data scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-12-20T19:33:04.580+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: financial_data_processing.process_dividends_data scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-12-20T19:33:04.582+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2023-12-20T19:33:04.662+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): process_dividends_data> on 2023-01-30 00:00:00+00:00
[2023-12-20T19:33:04.699+0000] {standard_task_runner.py:57} INFO - Started process 433 to run task
[2023-12-20T19:33:04.707+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'financial_data_processing', 'process_dividends_data', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '64', '--raw', '--subdir', 'DAGS_FOLDER/finacial.py', '--cfg-path', '/tmp/tmp103dm011']
[2023-12-20T19:33:04.714+0000] {standard_task_runner.py:85} INFO - Job 64: Subtask process_dividends_data
[2023-12-20T19:33:05.079+0000] {task_command.py:416} INFO - Running <TaskInstance: financial_data_processing.process_dividends_data scheduled__2023-01-30T00:00:00+00:00 [running]> on host 50d04165f2ca
[2023-12-20T19:33:05.285+0000] {local_task_job_runner.py:115} ERROR - Received SIGTERM. Terminating subprocesses
[2023-12-20T19:33:05.440+0000] {process_utils.py:131} INFO - Sending 15 to group 433. PIDs of all processes in the group: [433]
[2023-12-20T19:33:05.488+0000] {process_utils.py:86} INFO - Sending the signal 15 to group 433
[2023-12-20T19:33:05.498+0000] {taskinstance.py:1632} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-12-20T19:33:05.640+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1518, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1647, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2285, in render_templates
    original_task.render_template_fields(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1242, in render_template_fields
    jinja_env = self.get_template_env()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/abstractoperator.py", line 661, in get_template_env
    return super().get_template_env(dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/template/templater.py", line 55, in get_template_env
    return dag.get_template_env(force_sandboxed=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 1571, in get_template_env
    env = airflow.templates.SandboxedEnvironment(**jinja_env_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/templates.py", line 31, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/sandbox.py", line 253, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/environment.py", line 363, in __init__
    self.extensions = load_extensions(self, extensions)
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/environment.py", line 117, in load_extensions
    extension = t.cast(t.Type["Extension"], import_string(extension))
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/utils.py", line 149, in import_string
    return getattr(__import__(module, None, None, [obj]), obj)
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/ext.py", line 649, in <module>
    t.Tuple[int, str, t.Union[t.Optional[str], t.Tuple[t.Optional[str], ...]]]
  File "/usr/local/lib/python3.8/typing.py", line 258, in inner
    return cached(*args, **kwds)
  File "/usr/local/lib/python3.8/typing.py", line 330, in __hash__
    return hash((self._name,))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1634, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-12-20T19:33:05.678+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=financial_data_processing, task_id=process_dividends_data, execution_date=20230130T000000, start_date=20231220T193304, end_date=20231220T193305
[2023-12-20T19:33:05.970+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 64 for task process_dividends_data (Task received SIGTERM signal; 433)
[2023-12-20T19:33:06.090+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=433, status='terminated', exitcode=1, started='19:33:04') (433) terminated with exit code 1
[2023-12-20T19:33:06.096+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 143
[2023-12-20T19:33:06.309+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
